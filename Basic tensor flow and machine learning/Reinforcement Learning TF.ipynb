{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOX0T+yIRxbjOlOAzC2m8wS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5bc91786688b4ad5b5d4037c3ab27a51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c4f25736a45d49c5944c2e68aca7e3bd","IPY_MODEL_af82387e618646e9974904bdbdd6284d","IPY_MODEL_5155d56a1e4d402aa33d0284eca9b409"],"layout":"IPY_MODEL_6b0d5636660c44b0a4107057d4d8734b"}},"c4f25736a45d49c5944c2e68aca7e3bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_590c848b8c1c4c35af4ca062cf3d0ac7","placeholder":"​","style":"IPY_MODEL_66c8a8c7bc864683baa73adb5e33afed","value":"100%"}},"af82387e618646e9974904bdbdd6284d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c96cd30d3f39404c9589c948e08d43a1","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f76935ccdda49eeb82e4f17acbbe8f5","value":10000}},"5155d56a1e4d402aa33d0284eca9b409":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d6cc53a589944f78327d03a9156a5be","placeholder":"​","style":"IPY_MODEL_1ed119d7e1474ccbb945e55e8a234c54","value":" 10000/10000 [00:02&lt;00:00, 4391.24it/s]"}},"6b0d5636660c44b0a4107057d4d8734b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"590c848b8c1c4c35af4ca062cf3d0ac7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66c8a8c7bc864683baa73adb5e33afed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c96cd30d3f39404c9589c948e08d43a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f76935ccdda49eeb82e4f17acbbe8f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d6cc53a589944f78327d03a9156a5be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ed119d7e1474ccbb945e55e8a234c54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67892f28bb334106a22f9373cc8f5a4a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_608f5e8951d049239136ce44a53f4132","IPY_MODEL_ae784c7fa2834beaa9df442b5fa65a56","IPY_MODEL_1fbb612460bb47a595d7eab283d552d3"],"layout":"IPY_MODEL_c769b549481445dcb51cc799d184209a"}},"608f5e8951d049239136ce44a53f4132":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d54020b864fa4a13b7482d78b13c61c4","placeholder":"​","style":"IPY_MODEL_886ff8537f8c45d78cfda70fb17165bc","value":"100%"}},"ae784c7fa2834beaa9df442b5fa65a56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6be60790f464ffcb60a0742a96a52c3","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d18a40fd9e464bb48e34d430850f734d","value":100}},"1fbb612460bb47a595d7eab283d552d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0437e8c058d94ff6b87d36f61ae84b15","placeholder":"​","style":"IPY_MODEL_7406fd4906ae43368547f9781fca1939","value":" 100/100 [00:00&lt;00:00, 1579.44it/s]"}},"c769b549481445dcb51cc799d184209a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d54020b864fa4a13b7482d78b13c61c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"886ff8537f8c45d78cfda70fb17165bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6be60790f464ffcb60a0742a96a52c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d18a40fd9e464bb48e34d430850f734d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0437e8c058d94ff6b87d36f61ae84b15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7406fd4906ae43368547f9781fca1939":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aXVrh6Q5gyld"},"outputs":[],"source":["#Reiforcement learning is a machine learning stategy where rather than feeding data to the model, the agent, come up with these examples itself, letting an agent to explote an environment\n","#Environment, agent, state, action and reward\n","#Environment what try to solve or to do\n","#Agent what's going to explore the environment\n","#State where are in the enviroment\n","#Action the way that it interacts with the environment \n","#Rewards what the agent is trying to maximize while it is in the environment\n","#The agent go through and navigate the environment, go through a bunch of different states of it, and determinate wich actions maximize the reward at every given state\n","#The agent receive a reward after take an action"]},{"cell_type":"code","source":["#Qlearning\n","#Create a matrix with the every single state as a row, and as the columns every single action that could be taken in the different states\n","#Predict the reward of each action in different states\n","#Local maxima,get stucked, its not able to kind of realize from this state, that it can move ant further and receive a much greater reward\n","#need to take random actions and let the agent explore the environment freely before lookin the values\n","#the agent can pick randon valid action or use the current q table to find best action\n","# Q[state,action]=Q[state,action]+α∗(reward+γ∗max(Q[newState,:])−Q[state,action]) #look for the next state, factor that into the calculation, α how much we can update each value,γ higher going to look towards the future more,\n","#α  stands for the Learning Rate, ensures that we dont update the table too much on every observation\n","#γ  stands for the Discount Factor find balance between finding really good rewards in our curren state and finding rewards in the next state\n","#Need to explore more in the start (high epsilon value: chance of picking a random action) and progressly decrease it"],"metadata":{"id":"sy0UkJQMkKcY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import gym\n","import random\n","import imageio\n","import os\n","\n","import pickle5 as pickle\n","from tqdm.notebook import tqdm"],"metadata":{"id":"ymDCZje8WDom","executionInfo":{"status":"ok","timestamp":1676793240530,"user_tz":180,"elapsed":406,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["%%capture\n","!pip install pyglet==1.5.1 \n","!apt install python-opengl\n","!apt install ffmpeg\n","!apt install xvfb\n","!pip3 install pyvirtualdisplay\n","\n","# Virtual display\n","from pyvirtualdisplay import Display\n","\n","virtual_display = Display(visible=0, size=(1400, 900))\n","virtual_display.start()"],"metadata":{"id":"24sq71K-bVmH","executionInfo":{"status":"ok","timestamp":1676792448896,"user_tz":180,"elapsed":40607,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install gym # We install the newest gym version for the Taxi-v3 \"rgb_array version\"\n","!pip install pygame\n","!pip install numpy\n","\n","!pip install huggingface_hub\n","!pip install pickle5\n","!pip install pyyaml==6.0 # avoid key error metadata\n","!pip install imageio imageio_ffmpeg"],"metadata":{"id":"6wgVClKGbk3R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the FrozenLake-v1 environment using 4x4 map and non-slippery version\n","env = gym.make(\"FrozenLake-v1\", map_name=\"4x4\", is_slippery=False) "],"metadata":{"id":"Z0YfUn9gb3pd","executionInfo":{"status":"ok","timestamp":1676792517152,"user_tz":180,"elapsed":534,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5cf64b01-6672-42bf-be2c-434878d4dd16"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]}]},{"cell_type":"code","source":["# We create our environment with gym.make(\"<name_of_the_environment>\")\n","env.reset()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nUJqYPnmb9ki","executionInfo":{"status":"ok","timestamp":1676792520193,"user_tz":180,"elapsed":386,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}},"outputId":"b85c815f-849e-4244-8a41-2d7991104e60"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["print(env.observation_space.n)   # get number of states\n","print(env.action_space.n)   # get number of actions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DLTxkDjBWaUH","executionInfo":{"status":"ok","timestamp":1676792522618,"user_tz":180,"elapsed":532,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}},"outputId":"76b04edd-6814-4779-fb1e-37278f3dccdb"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["16\n","4\n"]}]},{"cell_type":"code","source":["print(\"\\n _____ACTION SPACE_____ \\n\")\n","print(\"Action Space Shape\", env.action_space.n)\n","print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gfmL8AYzWdsX","executionInfo":{"status":"ok","timestamp":1676792524413,"user_tz":180,"elapsed":3,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}},"outputId":"f9447149-4cf2-4bf4-c6ee-137f384f8ebc"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," _____ACTION SPACE_____ \n","\n","Action Space Shape 4\n","Action Space Sample 2\n"]}]},{"cell_type":"code","source":["#Initialize Q-table\n","state_space = env.observation_space.n\n","print(\"There are \", state_space, \" possible states\")\n","\n","action_space = env.action_space.n\n","print(\"There are \", action_space, \" possible actions\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LVE09y8WnUZn","executionInfo":{"status":"ok","timestamp":1676792544631,"user_tz":180,"elapsed":3,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}},"outputId":"d2ce48ed-bcdb-4eb9-b3b3-80fa129325da"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["There are  16  possible states\n","There are  4  possible actions\n"]}]},{"cell_type":"code","source":["# Let's create our Qtable of size (state_space, action_space) and initialized each values at 0 using np.zeros\n","def initialize_q_table(state_space, action_space):\n","  Qtable = np.zeros((state_space, action_space))\n","  return Qtable"],"metadata":{"id":"KZ-GwxYtnd3R","executionInfo":{"status":"ok","timestamp":1676792587992,"user_tz":180,"elapsed":390,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["Qtable_frozenlake = initialize_q_table(state_space, action_space)"],"metadata":{"id":"aEW7hHBEnmhS","executionInfo":{"status":"ok","timestamp":1676792590383,"user_tz":180,"elapsed":2,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["#Define the epsilon value\n","def epsilon_greedy_policy(Qtable, state, epsilon):\n","  # Randomly generate a number between 0 and 1\n","  random_int = random.uniform(0,1)\n","  # if random_int > greater than epsilon --> exploitation\n","  if random_int > epsilon:\n","    # Take the action with the highest value given a state\n","    # np.argmax can be useful here\n","    action = np.argmax(Qtable[state])\n","  # else --> exploration\n","  else:\n","    action = env.action_space.sample()\n","  \n","  return action"],"metadata":{"id":"dyFPygnNoHjo","executionInfo":{"status":"ok","timestamp":1676792646386,"user_tz":180,"elapsed":2,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["#Define the greedy policy\n","def greedy_policy(Qtable, state):\n","  # Exploitation: take the action with the highest state, action value\n","  action = np.argmax(Qtable[state])\n","  \n","  return action"],"metadata":{"id":"YJD83SWvoWlN","executionInfo":{"status":"ok","timestamp":1676792753270,"user_tz":180,"elapsed":817,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["#Define the parameters\n","\n","# Training parameters\n","n_training_episodes = 10000  # Total training episodes\n","learning_rate = 0.7          # Learning rate\n","\n","# Evaluation parameters\n","n_eval_episodes = 100        # Total number of test episodes\n","\n","# Environment parameters\n","env_id = \"FrozenLake-v1\"     # Name of the environment\n","max_steps = 99               # Max steps per episode\n","gamma = 0.95                 # Discounting rate\n","eval_seed = []               # The evaluation seed of the environment\n","\n","# Exploration parameters\n","max_epsilon = 1.0             # Exploration probability at start\n","min_epsilon = 0.05            # Minimum exploration probability \n","decay_rate = 0.0005            # Exponential decay rate for exploration prob"],"metadata":{"id":"2ZKUwl70owIv","executionInfo":{"status":"ok","timestamp":1676792769654,"user_tz":180,"elapsed":417,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["#Create the model\n","\n","def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n","  for episode in tqdm(range(n_training_episodes)):\n","    # Reduce epsilon (because we need less and less exploration)\n","    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n","    # Reset the environment\n","    state = env.reset()\n","    step = 0\n","    done = False\n","\n","    # repeat\n","    for step in range(max_steps):\n","      # Choose the action At using epsilon greedy policy\n","      action = epsilon_greedy_policy(Qtable, state, epsilon)\n","\n","      # Take action At and observe Rt+1 and St+1\n","      # Take the action (a) and observe the outcome state(s') and reward (r)\n","      new_state, reward, done, info = env.step(action)\n","\n","      # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n","      Qtable[state][action] = Qtable[state][action] + learning_rate * (reward + gamma * np.max(Qtable[new_state]) - Qtable[state][action])   \n","\n","      # If done, finish the episode\n","      if done:\n","        break\n","      \n","      # Our state is the new state\n","      state = new_state\n","  return Qtable"],"metadata":{"id":"GXoi9_KDo2Ax","executionInfo":{"status":"ok","timestamp":1676792796653,"user_tz":180,"elapsed":432,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["#Train the Qlearning agent\n","\n","Qtable_frozenlake = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_frozenlake)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["5bc91786688b4ad5b5d4037c3ab27a51","c4f25736a45d49c5944c2e68aca7e3bd","af82387e618646e9974904bdbdd6284d","5155d56a1e4d402aa33d0284eca9b409","6b0d5636660c44b0a4107057d4d8734b","590c848b8c1c4c35af4ca062cf3d0ac7","66c8a8c7bc864683baa73adb5e33afed","c96cd30d3f39404c9589c948e08d43a1","6f76935ccdda49eeb82e4f17acbbe8f5","5d6cc53a589944f78327d03a9156a5be","1ed119d7e1474ccbb945e55e8a234c54"]},"id":"2-Ep1ckSpJsd","executionInfo":{"status":"ok","timestamp":1676792960804,"user_tz":180,"elapsed":3366,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}},"outputId":"3738af50-e3d9-42ba-b2bb-c545e95c5c14"},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bc91786688b4ad5b5d4037c3ab27a51"}},"metadata":{}}]},{"cell_type":"code","source":["Qtable_frozenlake"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xnMio6XXplzk","executionInfo":{"status":"ok","timestamp":1676792981128,"user_tz":180,"elapsed":386,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}},"outputId":"7d4b35e9-2e8a-4d2d-ad21-e577509957be"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.73509189, 0.77378094, 0.77378094, 0.73509189],\n","       [0.73509189, 0.        , 0.81450625, 0.77378094],\n","       [0.77378094, 0.857375  , 0.77378094, 0.81450625],\n","       [0.81450625, 0.        , 0.77378094, 0.77378094],\n","       [0.77378094, 0.81450625, 0.        , 0.73509189],\n","       [0.        , 0.        , 0.        , 0.        ],\n","       [0.        , 0.9025    , 0.        , 0.81450625],\n","       [0.        , 0.        , 0.        , 0.        ],\n","       [0.81450625, 0.        , 0.857375  , 0.77378094],\n","       [0.81450625, 0.9025    , 0.9025    , 0.        ],\n","       [0.857375  , 0.95      , 0.        , 0.857375  ],\n","       [0.        , 0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        ],\n","       [0.        , 0.9025    , 0.95      , 0.857375  ],\n","       [0.9025    , 0.95      , 1.        , 0.9025    ],\n","       [0.        , 0.        , 0.        , 0.        ]])"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["#Define the evaluation method\n","\n","def evaluate_agent(env, max_steps, n_eval_episodes, Q, seed):\n","  \"\"\"\n","  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n","  :param env: The evaluation environment\n","  :param n_eval_episodes: Number of episode to evaluate the agent\n","  :param Q: The Q-table\n","  :param seed: The evaluation seed array (for taxi-v3)\n","  \"\"\"\n","  episode_rewards = []\n","  for episode in tqdm(range(n_eval_episodes)):\n","    if seed:\n","      state = env.reset(seed=seed[episode])\n","    else:\n","      state = env.reset()\n","    step = 0\n","    done = False\n","    total_rewards_ep = 0\n","    \n","    for step in range(max_steps):\n","      # Take the action (index) that have the maximum expected future reward given that state\n","      action = np.argmax(Q[state][:])\n","      new_state, reward, done, info = env.step(action)\n","      total_rewards_ep += reward\n","        \n","      if done:\n","        break\n","      state = new_state\n","    episode_rewards.append(total_rewards_ep)\n","  mean_reward = np.mean(episode_rewards)\n","  std_reward = np.std(episode_rewards)\n","\n","  return mean_reward, std_reward"],"metadata":{"id":"bZGJf4b7poc5","executionInfo":{"status":"ok","timestamp":1676793000580,"user_tz":180,"elapsed":2,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Evaluate our Agent\n","mean_reward, std_reward = evaluate_agent(env, max_steps, n_eval_episodes, Qtable_frozenlake, eval_seed)\n","print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["67892f28bb334106a22f9373cc8f5a4a","608f5e8951d049239136ce44a53f4132","ae784c7fa2834beaa9df442b5fa65a56","1fbb612460bb47a595d7eab283d552d3","c769b549481445dcb51cc799d184209a","d54020b864fa4a13b7482d78b13c61c4","886ff8537f8c45d78cfda70fb17165bc","a6be60790f464ffcb60a0742a96a52c3","d18a40fd9e464bb48e34d430850f734d","0437e8c058d94ff6b87d36f61ae84b15","7406fd4906ae43368547f9781fca1939"]},"id":"J7-1WVCzp5BL","executionInfo":{"status":"ok","timestamp":1676793063408,"user_tz":180,"elapsed":578,"user":{"displayName":"santiago lucero","userId":"03286679709682630982"}},"outputId":"db1d6a56-11b5-4ae2-ae07-015c507ff6f3"},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67892f28bb334106a22f9373cc8f5a4a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mean_reward=1.00 +/- 0.00\n"]}]}]}